{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resume Phrase Matcher code\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "\n",
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP_Resume/Candidate_Resume\\\\Resume.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to read resumes from the folder one by one\n",
    "mypath='NLP_Resume/Candidate_Resume' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "    countpage = fileReader.getNumPages()\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:    \n",
    "        pageObj = fileReader.getPage(count)\n",
    "        count +=1\n",
    "        t = pageObj.extractText()\n",
    "        print (t)\n",
    "        text.append(t)\n",
    "    return text\n",
    "\n",
    "#function to read resume ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[svm, random forest, decision trees]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dict = pd.read_csv('NLP_Resume/Candidate_Resume/template_new.csv')\n",
    "stats_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "stats_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"',\n",
       " '#',\n",
       " '$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'BES',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'GW',\n",
       " 'HVS',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NIL',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SP',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '_SP',\n",
       " '``',\n",
       " 'that',\n",
       " 'if',\n",
       " 'as',\n",
       " 'because',\n",
       " 'while',\n",
       " 'since',\n",
       " 'like',\n",
       " 'so',\n",
       " 'than',\n",
       " 'whether',\n",
       " 'although',\n",
       " 'though',\n",
       " 'unless',\n",
       " 'once',\n",
       " 'cause',\n",
       " 'upon',\n",
       " 'till',\n",
       " 'whereas',\n",
       " 'whilst',\n",
       " 'except',\n",
       " 'despite',\n",
       " 'wether',\n",
       " 'but',\n",
       " 'becuse',\n",
       " 'whie',\n",
       " 'it',\n",
       " 'w/out',\n",
       " 'albeit',\n",
       " 'save',\n",
       " 'besides',\n",
       " 'becouse',\n",
       " 'coz',\n",
       " 'til',\n",
       " 'ask',\n",
       " \"i'd\",\n",
       " 'out',\n",
       " 'near',\n",
       " 'seince',\n",
       " 'tho',\n",
       " 'sice',\n",
       " 'will',\n",
       " 'That',\n",
       " 'If',\n",
       " 'As',\n",
       " 'Because',\n",
       " 'While',\n",
       " 'Since',\n",
       " 'Like',\n",
       " 'So',\n",
       " 'Than',\n",
       " 'Whether',\n",
       " 'Although',\n",
       " 'Though',\n",
       " 'Unless',\n",
       " 'Once',\n",
       " 'Cause',\n",
       " 'Upon',\n",
       " 'Till',\n",
       " 'Whereas',\n",
       " 'Whilst',\n",
       " 'Except',\n",
       " 'Despite',\n",
       " 'Wether',\n",
       " 'But',\n",
       " 'Becuse',\n",
       " 'Whie',\n",
       " 'It',\n",
       " 'W/Out',\n",
       " 'Albeit',\n",
       " 'Save',\n",
       " 'Besides',\n",
       " 'Becouse',\n",
       " 'Coz',\n",
       " 'Til',\n",
       " 'Ask',\n",
       " \"I'D\",\n",
       " 'Out',\n",
       " 'Near',\n",
       " 'Seince',\n",
       " 'Tho',\n",
       " 'Sice',\n",
       " 'Will',\n",
       " 'something',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'nothing',\n",
       " 'someone',\n",
       " 'everything',\n",
       " 'everyone',\n",
       " 'everybody',\n",
       " 'nobody',\n",
       " 'somebody',\n",
       " 'anybody',\n",
       " 'any1',\n",
       " 'Something',\n",
       " 'Anyone',\n",
       " 'Anything',\n",
       " 'Nothing',\n",
       " 'Someone',\n",
       " 'Everything',\n",
       " 'Everyone',\n",
       " 'Everybody',\n",
       " 'Nobody',\n",
       " 'Somebody',\n",
       " 'Anybody',\n",
       " 'Any1',\n",
       " '-PRON-',\n",
       " 'I',\n",
       " 'me',\n",
       " 'you',\n",
       " 'he',\n",
       " 'him',\n",
       " 'she',\n",
       " 'her',\n",
       " 'we',\n",
       " 'us',\n",
       " 'they',\n",
       " 'them',\n",
       " 'mine',\n",
       " 'his',\n",
       " 'hers',\n",
       " 'its',\n",
       " 'ours',\n",
       " 'yours',\n",
       " 'theirs',\n",
       " 'myself',\n",
       " 'yourself',\n",
       " 'himself',\n",
       " 'herself',\n",
       " 'itself',\n",
       " 'themself',\n",
       " 'ourselves',\n",
       " 'yourselves',\n",
       " 'themselves',\n",
       " 'Me',\n",
       " 'You',\n",
       " 'He',\n",
       " 'Him',\n",
       " 'She',\n",
       " 'Her',\n",
       " 'We',\n",
       " 'Us',\n",
       " 'They',\n",
       " 'Them',\n",
       " 'Mine',\n",
       " 'His',\n",
       " 'Hers',\n",
       " 'Its',\n",
       " 'Ours',\n",
       " 'Yours',\n",
       " 'Theirs',\n",
       " 'Myself',\n",
       " 'Yourself',\n",
       " 'Himself',\n",
       " 'Herself',\n",
       " 'Itself',\n",
       " 'Themself',\n",
       " 'Ourselves',\n",
       " 'Yourselves',\n",
       " 'Themselves',\n",
       " 'my',\n",
       " 'your',\n",
       " 'our',\n",
       " 'their',\n",
       " 'My',\n",
       " 'Your',\n",
       " 'Our',\n",
       " 'Their',\n",
       " 'not',\n",
       " \"n't\",\n",
       " 'nt',\n",
       " 'n’t',\n",
       " 'Not',\n",
       " \"N'T\",\n",
       " 'Nt',\n",
       " 'N’T',\n",
       " 'be',\n",
       " 'have',\n",
       " 'do',\n",
       " 'get',\n",
       " 'of',\n",
       " 'am',\n",
       " 'are',\n",
       " \"'ve\",\n",
       " 'Be',\n",
       " 'Have',\n",
       " 'Do',\n",
       " 'Get',\n",
       " 'Of',\n",
       " 'Am',\n",
       " 'Are',\n",
       " \"'Ve\",\n",
       " 'been',\n",
       " 'Been',\n",
       " 'being',\n",
       " 'Being',\n",
       " 'is',\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " 'has',\n",
       " 'does',\n",
       " 'Is',\n",
       " \"'Re\",\n",
       " \"'S\",\n",
       " 'Has',\n",
       " 'Does',\n",
       " \"'m\",\n",
       " \"'d\",\n",
       " \"'M\",\n",
       " \"'D\",\n",
       " 'was',\n",
       " 'were',\n",
       " 'did',\n",
       " 'had',\n",
       " 'Was',\n",
       " 'Were',\n",
       " 'Did',\n",
       " 'Had',\n",
       " '\\t',\n",
       " 'en',\n",
       " '\\n',\n",
       " ' ',\n",
       " '\")',\n",
       " '\"',\n",
       " \"'\",\n",
       " \"'Cause\",\n",
       " \"'cause\",\n",
       " 'use',\n",
       " \"'Xxxxx\",\n",
       " \"'Cos\",\n",
       " \"'cos\",\n",
       " 'Cos',\n",
       " \"'Xxx\",\n",
       " \"'Coz\",\n",
       " \"'coz\",\n",
       " \"'Cuz\",\n",
       " \"'cuz\",\n",
       " 'Cuz',\n",
       " \"'X\",\n",
       " \"'bout\",\n",
       " 'about',\n",
       " \"'xxxx\",\n",
       " 'cos',\n",
       " \"'xxx\",\n",
       " 'cuz',\n",
       " \"'x\",\n",
       " \"'em\",\n",
       " \"'xx\",\n",
       " \"'ll\",\n",
       " \"'nuff\",\n",
       " 'enough',\n",
       " 'uff',\n",
       " '(*_*)',\n",
       " '(',\n",
       " '_*)',\n",
       " '(-8',\n",
       " '(-d',\n",
       " '(-:',\n",
       " '(-;',\n",
       " '(-_-)',\n",
       " '_-)',\n",
       " '(._.)',\n",
       " '_.)',\n",
       " '(:',\n",
       " '(;',\n",
       " '(=',\n",
       " '(>_<)',\n",
       " '_<)',\n",
       " '(^_^)',\n",
       " '_^)',\n",
       " '(o:',\n",
       " '(x:',\n",
       " '(¬_¬)',\n",
       " '_¬)',\n",
       " '(ಠ_ಠ)',\n",
       " '_ಠ)',\n",
       " '(x_x)',\n",
       " '(╯°□°）╯︵┻━┻',\n",
       " '┻━┻',\n",
       " ')-:',\n",
       " ')',\n",
       " '):',\n",
       " '-_-',\n",
       " '-',\n",
       " '-__-',\n",
       " '__-',\n",
       " '._.',\n",
       " '0.0',\n",
       " '0',\n",
       " 'd.d',\n",
       " '0.o',\n",
       " 'd.x',\n",
       " '0_0',\n",
       " 'd_d',\n",
       " '0_o',\n",
       " 'd_x',\n",
       " '10',\n",
       " '1',\n",
       " 'dd',\n",
       " 'a.m.',\n",
       " 'a',\n",
       " '.m.',\n",
       " 'x.x.',\n",
       " 'xx',\n",
       " 'p.m.',\n",
       " 'p',\n",
       " 'pm',\n",
       " '11',\n",
       " '12',\n",
       " 'd',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8)',\n",
       " '8',\n",
       " 'd)',\n",
       " '8-)',\n",
       " 'd-)',\n",
       " '8-D',\n",
       " '8-d',\n",
       " 'd-X',\n",
       " '8D',\n",
       " '8d',\n",
       " 'dX',\n",
       " '9',\n",
       " \":'(\",\n",
       " \":')\",\n",
       " \":'-(\",\n",
       " \"'-(\",\n",
       " \":'-)\",\n",
       " \"'-)\",\n",
       " ':(',\n",
       " ':((',\n",
       " ':(((',\n",
       " '(((',\n",
       " ':()',\n",
       " ':)',\n",
       " ':))',\n",
       " ':)))',\n",
       " ')))',\n",
       " ':*',\n",
       " ':-(',\n",
       " ':-((',\n",
       " '-((',\n",
       " ':-(((',\n",
       " ':-)',\n",
       " ':-))',\n",
       " '-))',\n",
       " ':-)))',\n",
       " ':-*',\n",
       " ':-/',\n",
       " ':-0',\n",
       " ':-d',\n",
       " ':-3',\n",
       " ':->',\n",
       " ':-D',\n",
       " ':-X',\n",
       " ':-O',\n",
       " ':-o',\n",
       " ':-P',\n",
       " ':-p',\n",
       " ':-x',\n",
       " ':-]',\n",
       " ':-|',\n",
       " ':-}',\n",
       " ':/',\n",
       " ':0',\n",
       " ':d',\n",
       " ':1',\n",
       " ':3',\n",
       " ':>',\n",
       " ':D',\n",
       " ':X',\n",
       " ':O',\n",
       " ':o',\n",
       " ':P',\n",
       " ':p',\n",
       " ':x',\n",
       " ':]',\n",
       " ':o)',\n",
       " ':x)',\n",
       " ':|',\n",
       " ':}',\n",
       " ':’(',\n",
       " ':’)',\n",
       " ':’-(',\n",
       " '’-(',\n",
       " ':’-)',\n",
       " '’-)',\n",
       " ';)',\n",
       " ';',\n",
       " ';-)',\n",
       " ';-D',\n",
       " ';-d',\n",
       " ';-X',\n",
       " ';D',\n",
       " ';d',\n",
       " ';X',\n",
       " ';_;',\n",
       " '<.<',\n",
       " '<',\n",
       " '</3',\n",
       " '</d',\n",
       " '<3',\n",
       " '<d',\n",
       " '<33',\n",
       " '<dd',\n",
       " '<333',\n",
       " '333',\n",
       " '<ddd',\n",
       " '<space>',\n",
       " 'ce>',\n",
       " '<xxxx>',\n",
       " '=(',\n",
       " '=',\n",
       " '=)',\n",
       " '=/',\n",
       " '=3',\n",
       " '=d',\n",
       " '=D',\n",
       " '=X',\n",
       " '=|',\n",
       " '>.<',\n",
       " '>',\n",
       " '>.>',\n",
       " '>:(',\n",
       " '>:o',\n",
       " '>:x',\n",
       " '><(((*>',\n",
       " '(*>',\n",
       " '@_@',\n",
       " '@',\n",
       " 'Adm.',\n",
       " 'adm.',\n",
       " 'A',\n",
       " 'dm.',\n",
       " 'Xxx.',\n",
       " 'Ai',\n",
       " 'ai',\n",
       " 'Xx',\n",
       " 'n',\n",
       " \"x'x\",\n",
       " 'x’x',\n",
       " 'Ak.',\n",
       " 'Alaska',\n",
       " 'ak.',\n",
       " 'Xx.',\n",
       " 'Ala.',\n",
       " 'Alabama',\n",
       " 'ala.',\n",
       " 'la.',\n",
       " 'Apr.',\n",
       " 'April',\n",
       " 'apr.',\n",
       " 'pr.',\n",
       " 'Xxx',\n",
       " 'Ariz.',\n",
       " 'Arizona',\n",
       " 'ariz.',\n",
       " 'iz.',\n",
       " 'Xxxx.',\n",
       " 'Ark.',\n",
       " 'Arkansas',\n",
       " 'ark.',\n",
       " 'rk.',\n",
       " 'Aug.',\n",
       " 'August',\n",
       " 'aug.',\n",
       " 'ug.',\n",
       " 'Bros.',\n",
       " 'bros.',\n",
       " 'B',\n",
       " 'os.',\n",
       " \"C'm\",\n",
       " 'come',\n",
       " \"c'm\",\n",
       " 'C',\n",
       " \"X'x\",\n",
       " 'on',\n",
       " 'o',\n",
       " 'C++',\n",
       " 'c++',\n",
       " 'X++',\n",
       " 'Calif.',\n",
       " 'California',\n",
       " 'calif.',\n",
       " 'if.',\n",
       " 'Xxxxx.',\n",
       " 'Ca',\n",
       " 'can',\n",
       " 'ca',\n",
       " 'Can',\n",
       " 'xxx',\n",
       " 've',\n",
       " 'v',\n",
       " '’ve',\n",
       " '’',\n",
       " '’xx',\n",
       " 'Co.',\n",
       " 'co.',\n",
       " 'Colo.',\n",
       " 'Colorado',\n",
       " 'colo.',\n",
       " 'lo.',\n",
       " 'Conn.',\n",
       " 'Connecticut',\n",
       " 'conn.',\n",
       " 'nn.',\n",
       " 'Corp.',\n",
       " 'corp.',\n",
       " 'rp.',\n",
       " 'Could',\n",
       " 'could',\n",
       " 'uld',\n",
       " 'Xxxxx',\n",
       " 'C’m',\n",
       " 'c’m',\n",
       " 'X’x',\n",
       " 'D.C.',\n",
       " 'd.c.',\n",
       " 'D',\n",
       " '.C.',\n",
       " 'X.X.',\n",
       " 'Dare',\n",
       " 'dare',\n",
       " 'Xxxx',\n",
       " 'Dec.',\n",
       " 'December',\n",
       " 'dec.',\n",
       " 'ec.',\n",
       " 'Del.',\n",
       " 'Delaware',\n",
       " 'del.',\n",
       " 'el.',\n",
       " 'oes',\n",
       " 'Doin',\n",
       " 'doing',\n",
       " 'doin',\n",
       " 'oin',\n",
       " \"Doin'\",\n",
       " \"doin'\",\n",
       " \"in'\",\n",
       " \"Xxxx'\",\n",
       " 'Doin’',\n",
       " 'doin’',\n",
       " 'in’',\n",
       " 'Xxxx’',\n",
       " 'Dr.',\n",
       " 'dr.',\n",
       " 'E.G.',\n",
       " 'e.g.',\n",
       " 'E',\n",
       " '.G.',\n",
       " 'E.g.',\n",
       " '.g.',\n",
       " 'X.x.',\n",
       " 'Feb.',\n",
       " 'February',\n",
       " 'feb.',\n",
       " 'F',\n",
       " 'eb.',\n",
       " 'Fla.',\n",
       " 'Florida',\n",
       " 'fla.',\n",
       " 'Ga.',\n",
       " 'Georgia',\n",
       " 'ga.',\n",
       " 'G',\n",
       " 'Gen.',\n",
       " 'gen.',\n",
       " 'en.',\n",
       " 'Goin',\n",
       " 'go',\n",
       " 'going',\n",
       " 'goin',\n",
       " \"Goin'\",\n",
       " \"goin'\",\n",
       " 'Goin’',\n",
       " 'goin’',\n",
       " 'Gon',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'to',\n",
       " 'Got',\n",
       " 'got',\n",
       " 'ta',\n",
       " 't',\n",
       " 'Gov.',\n",
       " 'gov.',\n",
       " 'ov.',\n",
       " 'H',\n",
       " 'ave',\n",
       " 'Havin',\n",
       " 'having',\n",
       " 'havin',\n",
       " 'vin',\n",
       " \"Havin'\",\n",
       " \"havin'\",\n",
       " \"Xxxxx'\",\n",
       " 'Havin’',\n",
       " 'havin’',\n",
       " 'Xxxxx’',\n",
       " 'would',\n",
       " 'x',\n",
       " 'll',\n",
       " 'l',\n",
       " 's',\n",
       " '’d',\n",
       " '’x',\n",
       " '’ll',\n",
       " '’s',\n",
       " 'How',\n",
       " 'how',\n",
       " \"'y\",\n",
       " 're',\n",
       " 'r',\n",
       " '’y',\n",
       " '’re',\n",
       " 'i',\n",
       " 'going to',\n",
       " 'gonna',\n",
       " 'I.E.',\n",
       " 'i.e.',\n",
       " '.E.',\n",
       " 'I.e.',\n",
       " '.e.',\n",
       " 'Ia.',\n",
       " 'Iowa',\n",
       " 'ia.',\n",
       " 'Id.',\n",
       " 'Idaho',\n",
       " 'id.',\n",
       " 'Ill.',\n",
       " 'Illinois',\n",
       " 'ill.',\n",
       " 'll.',\n",
       " 'm',\n",
       " 'Inc.',\n",
       " 'inc.',\n",
       " 'nc.',\n",
       " 'Ind.',\n",
       " 'Indiana',\n",
       " 'ind.',\n",
       " 'nd.',\n",
       " '’m',\n",
       " 'Jan.',\n",
       " 'January',\n",
       " 'jan.',\n",
       " 'J',\n",
       " 'an.',\n",
       " 'Jr.',\n",
       " 'jr.',\n",
       " 'Jul.',\n",
       " 'July',\n",
       " 'jul.',\n",
       " 'ul.',\n",
       " 'Jun.',\n",
       " 'June',\n",
       " 'jun.',\n",
       " 'un.',\n",
       " 'Kan.',\n",
       " 'Kansas',\n",
       " 'kan.',\n",
       " 'K',\n",
       " 'Kans.',\n",
       " 'kans.',\n",
       " 'ns.',\n",
       " 'Ky.',\n",
       " 'Kentucky',\n",
       " 'ky.',\n",
       " 'La.',\n",
       " 'Louisiana',\n",
       " 'L',\n",
       " 'Let',\n",
       " 'let',\n",
       " 'Lovin',\n",
       " 'love',\n",
       " 'loving',\n",
       " 'lovin',\n",
       " \"Lovin'\",\n",
       " \"lovin'\",\n",
       " 'Lovin’',\n",
       " 'lovin’',\n",
       " 'Ltd.',\n",
       " 'ltd.',\n",
       " 'td.',\n",
       " \"Ma'am\",\n",
       " 'madam',\n",
       " \"ma'am\",\n",
       " 'M',\n",
       " \"'am\",\n",
       " \"Xx'xx\",\n",
       " 'Mar.',\n",
       " 'March',\n",
       " 'mar.',\n",
       " 'ar.',\n",
       " 'Mass.',\n",
       " 'Massachusetts',\n",
       " 'mass.',\n",
       " 'ss.',\n",
       " 'May.',\n",
       " 'May',\n",
       " 'may.',\n",
       " 'ay.',\n",
       " 'may',\n",
       " 'Ma’am',\n",
       " 'ma’am',\n",
       " '’am',\n",
       " 'Xx’xx',\n",
       " 'Md.',\n",
       " 'md.',\n",
       " 'Messrs.',\n",
       " 'messrs.',\n",
       " 'rs.',\n",
       " 'Mich.',\n",
       " 'Michigan',\n",
       " 'mich.',\n",
       " 'ch.',\n",
       " 'Might',\n",
       " 'might',\n",
       " 'ght',\n",
       " 'Minn.',\n",
       " 'Minnesota',\n",
       " 'minn.',\n",
       " 'Miss.',\n",
       " 'Mississippi',\n",
       " 'miss.',\n",
       " 'Mo.',\n",
       " 'mo.',\n",
       " 'Mont.',\n",
       " 'mont.',\n",
       " 'nt.',\n",
       " 'Mr.',\n",
       " 'mr.',\n",
       " 'Mrs.',\n",
       " 'mrs.',\n",
       " 'Ms.',\n",
       " 'ms.',\n",
       " 'Mt.',\n",
       " 'Mount',\n",
       " 'mt.',\n",
       " 'Must',\n",
       " 'must',\n",
       " 'ust',\n",
       " 'N.C.',\n",
       " 'North Carolina',\n",
       " 'n.c.',\n",
       " 'N',\n",
       " 'N.D.',\n",
       " 'North Dakota',\n",
       " 'n.d.',\n",
       " '.D.',\n",
       " 'N.H.',\n",
       " 'New Hampshire',\n",
       " 'n.h.',\n",
       " '.H.',\n",
       " 'N.J.',\n",
       " 'New Jersey',\n",
       " 'n.j.',\n",
       " '.J.',\n",
       " 'N.M.',\n",
       " 'New Mexico',\n",
       " 'n.m.',\n",
       " '.M.',\n",
       " 'N.Y.',\n",
       " 'New York',\n",
       " 'n.y.',\n",
       " '.Y.',\n",
       " 'Neb.',\n",
       " 'Nebraska',\n",
       " 'neb.',\n",
       " 'Nebr.',\n",
       " 'nebr.',\n",
       " 'br.',\n",
       " 'Need',\n",
       " 'need',\n",
       " 'eed',\n",
       " 'Nev.',\n",
       " 'Nevada',\n",
       " 'nev.',\n",
       " 'ev.',\n",
       " 'Nothin',\n",
       " 'nothin',\n",
       " 'hin',\n",
       " \"Nothin'\",\n",
       " \"nothin'\",\n",
       " 'Nothin’',\n",
       " 'nothin’',\n",
       " 'Nov.',\n",
       " 'November',\n",
       " 'nov.',\n",
       " 'Nuthin',\n",
       " 'nuthin',\n",
       " \"Nuthin'\",\n",
       " \"nuthin'\",\n",
       " 'Nuthin’',\n",
       " 'nuthin’',\n",
       " \"O'clock\",\n",
       " \"o'clock\",\n",
       " 'O',\n",
       " 'ock',\n",
       " \"X'xxxx\",\n",
       " 'O.O',\n",
       " 'o.o',\n",
       " 'X.X',\n",
       " 'O.o',\n",
       " 'X.x',\n",
       " 'O_O',\n",
       " 'o_o',\n",
       " 'X_X',\n",
       " 'O_o',\n",
       " 'X_x',\n",
       " 'Oct.',\n",
       " 'October',\n",
       " 'oct.',\n",
       " 'ct.',\n",
       " 'Okla.',\n",
       " 'Oklahoma',\n",
       " 'okla.',\n",
       " 'Ol',\n",
       " 'old',\n",
       " 'ol',\n",
       " \"Ol'\",\n",
       " \"ol'\",\n",
       " \"Xx'\",\n",
       " 'Ol’',\n",
       " 'ol’',\n",
       " 'Xx’',\n",
       " 'Ore.',\n",
       " 'Oregon',\n",
       " 'ore.',\n",
       " 're.',\n",
       " 'Ought',\n",
       " 'ought',\n",
       " 'O’clock',\n",
       " 'o’clock',\n",
       " 'X’xxxx',\n",
       " 'Pa.',\n",
       " 'Pennsylvania',\n",
       " 'pa.',\n",
       " 'P',\n",
       " 'Ph.D.',\n",
       " 'ph.d.',\n",
       " 'Xx.X.',\n",
       " 'Prof.',\n",
       " 'prof.',\n",
       " 'of.',\n",
       " 'Rep.',\n",
       " 'rep.',\n",
       " 'R',\n",
       " 'ep.',\n",
       " 'Rev.',\n",
       " 'rev.',\n",
       " 'S.C.',\n",
       " 'South Carolina',\n",
       " 's.c.',\n",
       " 'S',\n",
       " 'Sen.',\n",
       " 'sen.',\n",
       " 'Sep.',\n",
       " 'September',\n",
       " 'sep.',\n",
       " 'Sept.',\n",
       " 'sept.',\n",
       " 'pt.',\n",
       " 'Sha',\n",
       " 'shall',\n",
       " 'sha',\n",
       " 'Should',\n",
       " 'should',\n",
       " 'Somethin',\n",
       " 'somethin',\n",
       " \"Somethin'\",\n",
       " \"somethin'\",\n",
       " 'Somethin’',\n",
       " 'somethin’',\n",
       " 'St.',\n",
       " 'st.',\n",
       " 'Tenn.',\n",
       " 'Tennessee',\n",
       " 'tenn.',\n",
       " 'T',\n",
       " 'hat',\n",
       " 'There',\n",
       " 'there',\n",
       " 'ere',\n",
       " 'These',\n",
       " 'these',\n",
       " 'ese',\n",
       " 'hey',\n",
       " 'This',\n",
       " 'this',\n",
       " 'Those',\n",
       " 'those',\n",
       " 'ose',\n",
       " 'V.V',\n",
       " 'v.v',\n",
       " 'V',\n",
       " 'V_V',\n",
       " 'v_v',\n",
       " 'Va.',\n",
       " 'Virginia',\n",
       " 'va.',\n",
       " 'Wash.',\n",
       " 'Washington',\n",
       " 'wash.',\n",
       " 'W',\n",
       " 'sh.',\n",
       " 'What',\n",
       " 'what',\n",
       " 'When',\n",
       " 'when',\n",
       " 'hen',\n",
       " 'Where',\n",
       " 'where',\n",
       " 'Who',\n",
       " 'who',\n",
       " 'Why',\n",
       " 'why',\n",
       " 'Wis.',\n",
       " 'Wisconsin',\n",
       " 'wis.',\n",
       " 'is.',\n",
       " 'Wo',\n",
       " 'wo',\n",
       " 'Would',\n",
       " 'XD',\n",
       " 'xd',\n",
       " 'XDD',\n",
       " 'xdd',\n",
       " 'XXX',\n",
       " 'Y',\n",
       " '[-:',\n",
       " '[',\n",
       " '[:',\n",
       " '\\\\\")',\n",
       " '\\\\',\n",
       " '\\\\n',\n",
       " '\\\\x',\n",
       " '\\\\t',\n",
       " '^_^',\n",
       " '^',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Abhishek Kumar \n",
      "Pandey\n",
      " \n",
      "31, Beaufield Gardens, Maynooth, \n",
      "Co.Kildare, W23 Y5T7\n",
      "   \n",
      " \n",
      " \n",
      "+\n",
      "(\n",
      "353) \n",
      "892475998\n",
      " \n",
      " \n",
      " \n",
      "talkabhishekpandey\n",
      "@\n",
      "gmail\n",
      ".com\n",
      " \n",
      " \n",
      "www.linkedin.com/in/talkabhishekpandey\n",
      " \n",
      "https://github.com/abhishekkpandey1\n",
      "  \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Strong analytical thinker with problem\n",
      "-\n",
      "solving and presentation skills. Interested in the position of Data \n",
      "Scientist to utilize \n",
      "my 4 years of programming skills at Tata Consultancy Services \n",
      "\n",
      "Data Science and Analytics\n",
      ". Bringing hands\n",
      "-\n",
      "on experience in using advanced statistical techni\n",
      "ques and \n",
      "machine learning \n",
      "skill\n",
      "s.\n",
      " \n",
      "Skills\n",
      " \n",
      "Programming Language: Python, R\n",
      ", Java\n",
      ", HTML.\n",
      " \n",
      "Algorithms: Machine Learning, Deep Learning, Statistical Machine Learning\n",
      " \n",
      "Database: \n",
      "Oracle \n",
      "SQL\n",
      " \n",
      "Data Analytics Librari\n",
      "es: Numpy, Pandas, Sklearn, Spacy, \n",
      "Keras, Tensorflow, Matplotlib.\n",
      " \n",
      "Frameworks & Tools: Tableau, Jupyter, R Studio, Jenkins, Git, SVN.\n",
      " \n",
      "Servers: \n",
      "Jboss, Tomcat, \n",
      "Flask\n",
      " \n",
      "Operating System: Windows, Linux\n",
      " \n",
      "Project\n",
      " \n",
      "Amazon Reviews\n",
      " \n",
      "Sentiment Analysis (\n",
      "Real\n",
      "-\n",
      "time/Capston\n",
      "e \n",
      "Project present\n",
      " \n",
      "in GitHub):\n",
      " \n",
      "The key idea is to predict the potential sentiment of a body of \n",
      "movie review\n",
      " \n",
      "based on the textual \n",
      "content\n",
      " \n",
      "and predict whether the review is positive or negative\n",
      ".\n",
      " \n",
      "Used \n",
      "BeautifulSoup, contractions,\n",
      " \n",
      "Unicode \n",
      "data, CountVectorizer\n",
      ",\n",
      " \n",
      "and\n",
      " \n",
      "TfidfVectorizer\n",
      " \n",
      "in\n",
      "-\n",
      "text wrangling & feature engineering. Used \n",
      "Logistic \n",
      "Regression\n",
      " \n",
      "& Random Forest Classifier\n",
      " \n",
      "for prediction using classification report and confusion \n",
      "matrix.\n",
      " \n",
      " \n",
      "Fraudulent Credit Card Transaction\n",
      " \n",
      "Analysis\n",
      " \n",
      "(\n",
      "Real\n",
      "-\n",
      "time/Capstone \n",
      "Project pres\n",
      "ent \n",
      "in \n",
      "GitHub):\n",
      " \n",
      "Classification of Fraud/Not Fraud transactions with \n",
      "a \n",
      "highly imbalanced dataset\n",
      ".\n",
      " \n",
      "Used \n",
      "sub\n",
      "-\n",
      "sample\n",
      " \n",
      "and \n",
      "Random under\n",
      "-\n",
      "sampling\n",
      " \n",
      "to remove \n",
      "class imbalance\n",
      ". \n",
      "Anomaly detection and dimensionality reduction\n",
      " \n",
      "ha\n",
      "ve\n",
      " \n",
      "been implemented and \n",
      "GridSearchCV\n",
      " \n",
      "has bee\n",
      "n used to predict best scores from the classifiers.\n",
      " \n",
      "M\n",
      "easuring the accuracy using the \n",
      "Area Under the Precision\n",
      "-\n",
      "Recall Curve (AUPRC).\n",
      " \n",
      "Credit Card Dataset for Clustering\n",
      " \n",
      "(\n",
      "Real\n",
      "-\n",
      "time/Capstone \n",
      "Project present \n",
      "in GitHub):\n",
      " \n",
      "T\n",
      "o develop a customer segmentation to \n",
      "define marketing strategy. The\n",
      " \n",
      "sample Dataset summarizes the \n",
      "usage behavior of about 9000 active credit card\n",
      "holders d\n",
      "uring the last 6 months.\n",
      " \n",
      "Performed \n",
      "data \n",
      "wrangling, univariate analysis, outliers detected\n",
      ",\n",
      " \n",
      "and removal using z score\n",
      ", visualizing correlati\n",
      "on \n",
      "using \n",
      "a \n",
      "heat map\n",
      ",\n",
      " \n",
      "and \n",
      "applied k\n",
      "-\n",
      "means\n",
      " \n",
      "clustering to find the optimal value of cluster using \n",
      "the \n",
      "elbow \n",
      "method\n",
      ".\n",
      " \n",
      "\n",
      "2\n",
      " \n",
      " \n",
      "Insurance Premium Prediction \n",
      "(\n",
      "Real\n",
      "-\n",
      "time/Capstone \n",
      "Project present in GitHub):\n",
      " \n",
      "O\n",
      "bserve \n",
      "the \n",
      "relationship between individual features against their existing medical expenses to predict \n",
      "future medical expenses \n",
      "that help medical insurance to \n",
      "decide\n",
      " \n",
      "on charging the premium.\n",
      " \n",
      "Used EDA to \n",
      "understand the distribution of data and check \n",
      "the \n",
      "corr\n",
      "elation of features and target variables. Applied \n",
      "One Hot Encoding \n",
      "and after normalizing the features, applied Linear Regressor, Polynomial Regressor, \n",
      "Decision Tree Regressor\n",
      ",\n",
      " \n",
      "and Random Forest Regressor and predicted accuracy using R2 score, RMSE\n",
      ",\n",
      " \n",
      "and cross\n",
      "-\n",
      "validation.\n",
      " \n",
      "Work \n",
      "Experience\n",
      " \n",
      "JUNE 201\n",
      "6\n",
      " \n",
      "\n",
      " \n",
      "SE\n",
      "PTEMBER 2020\n",
      "-\n",
      " \n",
      "TATA CONSULTANCY SERVICES LIMITED\n",
      " \n",
      "Project\n",
      "-\n",
      " \n",
      "TCS Internal (Name: pFile Document Tracker application)\n",
      " \n",
      "Role: \n",
      "Developer\n",
      "-\n",
      " \n",
      "(Designation: \n",
      "S\n",
      "ystem Engineer\n",
      ")\n",
      " \n",
      "Worked for HR data management for all the TCS empl\n",
      "oyees\n",
      " \n",
      "with data integration from different \n",
      "application\n",
      "s\n",
      " \n",
      "and consolidating them to populate to HR users\n",
      ". \n",
      "Having hands\n",
      "-\n",
      "on knowledge in Oracle \n",
      "Database, Java, AngularJS, Jenkins CICD, HTML, and Linux commands. Worked on tools such as PL/SQL \n",
      "Developer, Eclipse, JBoss, Tomcat, Weblogic, SSH/WinSCP, Jenkins for CICD, Sonarqube, Maven, SVN, \n",
      "and Git.\n",
      " \n",
      "Project\n",
      "-\n",
      " \n",
      "TCS In\n",
      "ternal (Name: \n",
      "Tax Compliance Report Automation\n",
      " \n",
      "application)\n",
      " \n",
      "Developer\n",
      "-\n",
      " \n",
      "(Designation: Assistant System Engineer)\n",
      " \n",
      "Worked in Documentum technology, mostly on \n",
      "the \n",
      "database part. Handling tax\n",
      "-\n",
      "related data for TCS \n",
      "branches and its subsidiaries in \n",
      "the \n",
      "oracle database alo\n",
      "ng with the front end part in HTML and Java.\n",
      " \n",
      "Worked on tools such as PL/SQL Developer, Eclipse, JBoss, Tomcat, Weblogic\n",
      ", SSH/WinSCP, \n",
      "Sonarqube\n",
      ",\n",
      " \n",
      "and SVN\n",
      ".\n",
      " \n",
      "Project\n",
      "-\n",
      " \n",
      "TCS Internal (Name: API Bank Project\n",
      "-\n",
      " \n",
      "Training Project)\n",
      " \n",
      "Developer\n",
      "-\n",
      " \n",
      "(Designation: Assistant Syst\n",
      "em Engineer Trainee)\n",
      " \n",
      "Worked as a Trainee developer in \n",
      "the \n",
      "API Bank project (TCS Internal Training program) from June 2016 \n",
      "till Sept 2016 which had functionalities related to bank\n",
      "s\n",
      " \n",
      "like \n",
      "opening bank account, teller login\n",
      ",\n",
      " \n",
      "etc. Used \n",
      "HTML, CSS, bootstrap, Java\n",
      ",\n",
      " \n",
      "and \n",
      "Oracle Database.\n",
      " \n",
      "Education\n",
      " \n",
      "MAYNOOTH UNIVERSITY \n",
      "| M.SC DATA SCIENCE \n",
      "AND ANALYTICS\n",
      " \n",
      "(SEPTEMBER 2020\n",
      "-\n",
      " \n",
      "PR\n",
      "ESENT\n",
      ")\n",
      " \n",
      "Modules: \n",
      "Machine Learning & Neural Networks,\n",
      " \n",
      "Spatial Database, Statistical Modelling for \n",
      "Data Science, Linear Modelling, R for Data Analytics\n",
      ", Statis\n",
      "tical Machine Learning,\n",
      " \n",
      "etc.\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "(2012\n",
      "-\n",
      "16)\n",
      " \n",
      "Modules:\n",
      " \n",
      "Data Structures, C Programming, Soft Computing, \n",
      "Object\n",
      "-\n",
      "Oriented Programming \n",
      "Structure, Engineering Economics, MATLAB Project\n",
      ", \n",
      "etc.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "3\n",
      " \n",
      "Accolades\n",
      " \n",
      "IBM \n",
      "C\n",
      "ertified Data Science and AI certification (250+ hours course) with 5+ real\n",
      "-\n",
      "time projects in \n",
      "insurance, banking, sentiment analysis domains, etc.\n",
      " \n",
      "Bootcamp in Data Science and Machine Learning from Udemy (Certified)\n",
      ".\n",
      " \n",
      "Completed Tableau ce\n",
      "rtification from Udemy.\n",
      " \n",
      "Awarded with Special Initiative Award for the outstanding contribution \n",
      "to the organization \n",
      "and inspiring \n",
      "role model \n",
      "to the colleagues.\n",
      " \n",
      "Awarded with Special Achievement Award for the outstanding contribution to the organization.\n",
      " \n",
      "Decl\n",
      "aration\n",
      " \n",
      "I hereby declare that the above statements are true and correct to the best of my knowledge.\n",
      " \n",
      " \n",
      "Abhishek Kumar Pandey\n",
      " \n",
      "\n",
      "rule id DL\n",
      "span keras\n",
      "rule id ML\n",
      "span random forest\n",
      "rule id ML\n",
      "span random forest\n",
      "DL keras (1)\n",
      "ML random forest (2)\n",
      "  Candidate Name Subject         Keyword Count\n",
      "0         resume      DL          keras      1\n",
      "1         resume      ML  random forest      2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    keyword_dict = pd.read_csv('NLP_Resume/Candidate_Resume/template_new.csv')\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        print(\"rule id\",rule_id)\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        print(\"span\",span)\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    print(keywords)\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "    return(dataf)\n",
    "        \n",
    "#function ends\n",
    "        \n",
    "#code to execute/call the above functions\n",
    "\n",
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    dat = create_profile(file)\n",
    "    final_database = final_database.append(dat)\n",
    "    i +=1\n",
    "    print(final_database)\n",
    "\n",
    "    \n",
    "#code to count words under each category and visulaize it through Matplotlib\n",
    "\n",
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "#sample2=new_data.to_csv('sample.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-000b5b0b4a38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{i[0]} {i[1]} ({j})'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
